{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#29487d'> TOPIC </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy import optimize\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#29487d'> Linear Regression Algorithm</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X, y = (examples, features)\n",
    "## Theta = (thetas,)\n",
    "class LinearRegression():\n",
    "    def __init__(self, reg_lambda = 0, eta = 0.01, niter=1500,):\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.eta = eta\n",
    "        self.niter = niter\n",
    "        self.theta = None\n",
    "        self.cost = []\n",
    "###################  Train the model  ##################\n",
    "    def fit(self,X, y):\n",
    "        X = np.concatenate((np.ones((X.shape[0],1)), X),1)\n",
    "        reg_lambda = self.reg_lambda\n",
    "        m = len(y)\n",
    "###################  Compute Cost Function for Linear Regression #################\n",
    "        def _cost(theta):\n",
    "            J = 0\n",
    "            theta = theta.reshape(theta.shape[0],1) \n",
    "            reg_penalty = reg_lambda/(2/m) * (theta[1:] ** 2).sum()\n",
    "            J = float(1)/(2*m) * ((X.dot(theta) - y) ** 2).sum() +  reg_penalty\n",
    "            return J\n",
    "        def _grad(theta):\n",
    "            self.cost = []\n",
    "            reg_penalty = reg_lambda/(m) * (theta[1:]).sum()\n",
    "            theta = theta.reshape(theta.shape[0],1) \n",
    "            grad = 1/(m) * np.transpose(X).dot((X.dot(theta).reshape(y.shape[0],y.shape[1]) - y)) +  reg_penalty\n",
    "            grad.reshape(grad.shape[0],)\n",
    "            return grad\n",
    "        \n",
    "################### Broyden-Fletcher-Goldfarb-Shanno Algorithm ###################\n",
    "        ## use this algorithm to converge gradient\n",
    "        #theta = np.zeros((X.shape[1],1))\n",
    "        theta = np.random.rand(X.shape[1],1)\n",
    "        self.cost.append(_cost(theta))\n",
    "\n",
    "        for i in range(0,self.niter+1):\n",
    "            grad = _grad(theta)\n",
    "            theta = theta - self.eta * grad\n",
    "            self.cost.append(_cost(theta))\n",
    "            print('\\rIteration:  %d || Cost : %f'  % (i , _cost(theta)), flush=True,end='')\n",
    "#         [xopt, fopt, gopt, Bopt, func_calls, grad_calls, warnflg] = optimize.fmin_cg(f=_cost,\n",
    "#                                                                                        x0=init_theta,\n",
    "#                                                                                        fprime=_grad,\n",
    "#                                                                                        disp=True,\n",
    "#                                                                                        maxiter = self.niter,\n",
    "#                                                                                        full_output=True,\n",
    "#                                                                                        retall=False)\n",
    "#         #xopt = optimize.minimize(fun=_cost, x0=init_theta, method='CG', jac=_grad)\n",
    "        print('\\nTheta is: ', end='')\n",
    "        for i in range(0, theta.shape[0]):\n",
    "            print('%f, ' % theta[i], end='')\n",
    "        print()\n",
    "        self.theta = theta\n",
    "        \n",
    "###################  Predict the New Data  ##################\n",
    "    def predict(self,newData):\n",
    "        if len(newData.shape) == 1:\n",
    "            newData = newData.reshape(newData.shape[0],1)\n",
    "        newData = np.concatenate((np.ones((newData.shape[0],1)), newData),1)\n",
    "        return newData.dot(self.theta)\n",
    "    def getCost(self):\n",
    "        return self.cost\n",
    "    def set_eta(self, eta):\n",
    "        self.cost = []\n",
    "        self.eta = eta\n",
    "    def set_niter(self, niter):\n",
    "        self.niter=niter\n",
    "    def set_panelty(self, p):\n",
    "        self.reg_lambda = p\n",
    "    def get_theta(self):\n",
    "        return self.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduce to the Features\n",
    " - ### Pclass: Ticket class\n",
    " - ### Sex: sex\n",
    " - ### Sex: \n",
    "    - #### 1 = Male \n",
    "    - #### 0 = Female\n",
    " - ### SibSp: Number of siblings/spouses aboard the Titanic\n",
    " - ### Parch: Number of parents/children aboard the Titanic\n",
    " - ### Ticket: Ticket number\n",
    " - ### Fareï¼š Passenger fare\n",
    " - ### Cabin: Cabin number\n",
    " - ### Embarked: Port of Embarkation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-range the table\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[1:] + cols[:1]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked',\n",
       " 'PassengerId']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total rows in the data\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to convert the male to the dummy feature\n",
    "# The Sex columns will be is male or not.\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df_copy = df.values\n",
    "df_copy[:,3] = le.fit_transform(df_copy[:,3])\n",
    "\n",
    "df = pd.DataFrame(df_copy, columns=cols)\n",
    "\n",
    "# Since name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Survived Pclass                                               Name Sex Age  \\\n",
       "0        0      3                            Braund, Mr. Owen Harris   1  22   \n",
       "1        1      1  Cumings, Mrs. John Bradley (Florence Briggs Th...   0  38   \n",
       "2        1      3                             Heikkinen, Miss. Laina   0  26   \n",
       "3        1      1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   0  35   \n",
       "4        0      3                           Allen, Mr. William Henry   1  35   \n",
       "\n",
       "  SibSp Parch            Ticket     Fare Cabin Embarked PassengerId  \n",
       "0     1     0         A/5 21171     7.25   NaN        S           1  \n",
       "1     1     0          PC 17599  71.2833   C85        C           2  \n",
       "2     0     0  STON/O2. 3101282    7.925   NaN        S           3  \n",
       "3     1     0            113803     53.1  C123        S           4  \n",
       "4     0     0            373450     8.05   NaN        S           5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows that contains NaN : 708\n",
      "The percentage that contains NaN data : 0.794613\n"
     ]
    }
   ],
   "source": [
    "print(\"Total rows that contains NaN : %d\" % (df.shape[0] - df.dropna().shape[0]))\n",
    "print(\"The percentage that contains NaN data : %f\"% ((df.shape[0] - df.dropna().shape[0])/df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Survival distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1990b6a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Survived.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => WE can see we dont have any skewed class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The relation between Age and survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['Age'], df['Survived'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <font color='#29487d'> Check the Null Value</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#5b7cbb'>Count  How Many Rows have the NaN ( Null ) Values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       889\n",
       "PassengerId    891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see how many datas are available (Not NaN)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Survived Pclass                            Name Sex  Age SibSp Parch  \\\n",
       "0        0      3         Braund, Mr. Owen Harris   1   22     1     0   \n",
       "2        1      3          Heikkinen, Miss. Laina   0   26     0     0   \n",
       "4        0      3        Allen, Mr. William Henry   1   35     0     0   \n",
       "5        0      3                Moran, Mr. James   1  NaN     0     0   \n",
       "7        0      3  Palsson, Master. Gosta Leonard   1    2     3     1   \n",
       "\n",
       "             Ticket    Fare Cabin Embarked PassengerId  \n",
       "0         A/5 21171    7.25   NaN        S           1  \n",
       "2  STON/O2. 3101282   7.925   NaN        S           3  \n",
       "4            373450    8.05   NaN        S           5  \n",
       "5            330877  8.4583   NaN        Q           6  \n",
       "7            349909  21.075   NaN        S           8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the rows that has the null value\n",
    "df[df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Cabin', 'Embarked'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the number of NaN data in each columns\n",
    "null_columns=df.columns[df.isnull().any()]\n",
    "null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         177\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[null_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the name apparently is not related to the passenger surviv or not. We drop the 'Name' column\n",
    "df = df.drop('Name', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ticket doesnt have any null value <br>\n",
    "=> Every Passanger has the ticket, so survived or not is not related to the ticket<br>\n",
    "\n",
    "** Everyone has the same state: has ticket **<br>\n",
    "\n",
    "so we drop the tick column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Ticket', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Survived Pclass Sex Age SibSp Parch     Fare Cabin Embarked PassengerId\n",
       "0        0      3   1  22     1     0     7.25   NaN        S           1\n",
       "1        1      1   0  38     1     0  71.2833   C85        C           2\n",
       "2        1      3   0  26     0     0    7.925   NaN        S           3\n",
       "3        1      1   0  35     1     0     53.1  C123        S           4\n",
       "4        0      3   1  35     0     0     8.05   NaN        S           5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cabin only has the 204 not NaN, so we have to consider that do we really need Cabin ? <br><br>\n",
    "We drop the are carbin value here first. After we can see the accuracy of this data <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Survived Pclass Sex Age SibSp Parch     Fare Embarked PassengerId\n",
       "0        0      3   1  22     1     0     7.25        S           1\n",
       "1        1      1   0  38     1     0  71.2833        C           2\n",
       "2        1      3   0  26     0     0    7.925        S           3\n",
       "3        1      1   0  35     1     0     53.1        S           4\n",
       "4        0      3   1  35     0     0     8.05        S           5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('Cabin', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       889\n",
       "Pclass         889\n",
       "Sex            889\n",
       "Age            712\n",
       "SibSp          889\n",
       "Parch          889\n",
       "Fare           889\n",
       "Embarked       889\n",
       "PassengerId    889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['Embarked'])  \n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the relation between Embarked and Suvival rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1bafd5c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "df.Embarked.value_counts().plot(kind='bar')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "df.Survived[df.Embarked == 'S'].value_counts().sort_index().plot(kind='bar', color='#1f77b4',label = 'S')\n",
    "df.Survived[df.Embarked == 'C'].value_counts().sort_index().plot(kind='bar', color='#ff7f0e', label='C')\n",
    "df.Survived[df.Embarked == 'Q'].value_counts().sort_index().plot(kind='bar', color='#2ca02c',label = 'Q')\n",
    "plt.title(\"Who Survived? with respect to the location they embark, (raw value counts) \")\n",
    "plt.xlabel('Survived?')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#1f77b4'> We can see this class seem reasonable, which equally distribute\n",
    "<p> We can remain this feature</p>\n",
    "<p> Because it is classical value, we convert it to the dummy feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we convert to the dummy feature\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder(categorical_features=['Embarked'])\n",
    "\n",
    "df_copy = df.values\n",
    "df_copy[:,7] = le.fit_transform(df_copy[:,7])\n",
    "a = np.zeros((df_copy.shape[0],1))\n",
    "b = np.zeros((df_copy.shape[0],1))\n",
    "c = np.zeros((df_copy.shape[0],1))\n",
    "for i in range(0, df_copy.shape[0]):\n",
    "    if df_copy[i,7] == 0:\n",
    "        a[i] = 1\n",
    "    elif df_copy[i,7] == 1:\n",
    "        b[i] = 1\n",
    "    elif df_copy[i,7] == 2:\n",
    "        c[i] = 1\n",
    "    else:\n",
    "        a[i] = 0\n",
    "        b[i] = 0\n",
    "        c[i] = 0\n",
    "df_copy[:,7] = a[:,0]            \n",
    "df_copy = np.append(df_copy, b, 1)\n",
    "df_copy = np.append(df_copy, c, 1)\n",
    "cols[7] = 'Embarked:C'\n",
    "cols.append('Embarked:Q')\n",
    "cols.append('Embarked:S')\n",
    "df = pd.DataFrame(df_copy, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked:C</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Embarked:Q</th>\n",
       "      <th>Embarked:S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Survived Pclass Sex Age SibSp Parch     Fare Embarked:C PassengerId  \\\n",
       "0        0      3   1  22     1     0     7.25          0           1   \n",
       "1        1      1   0  38     1     0  71.2833          1           2   \n",
       "2        1      3   0  26     0     0    7.925          0           3   \n",
       "3        1      1   0  35     1     0     53.1          0           4   \n",
       "4        0      3   1  35     0     0     8.05          0           5   \n",
       "\n",
       "  Embarked:Q Embarked:S  \n",
       "0          0          1  \n",
       "1          0          0  \n",
       "2          0          1  \n",
       "3          0          1  \n",
       "4          0          1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we convert to the dummy feature\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder(categorical_features=['Pclass'])\n",
    "\n",
    "df_copy = df.values\n",
    "df_copy[:,7] = le.fit_transform(df_copy[:,7])\n",
    "a = np.zeros((df_copy.shape[0],1))\n",
    "b = np.zeros((df_copy.shape[0],1))\n",
    "c = np.zeros((df_copy.shape[0],1))\n",
    "for i in range(0, df_copy.shape[0]):\n",
    "    if df_copy[i,7] == 0:\n",
    "        a[i] = 1\n",
    "    elif df_copy[i,7] == 1:\n",
    "        b[i] = 1\n",
    "    elif df_copy[i,7] == 2:\n",
    "        c[i] = 1\n",
    "    else:\n",
    "        a[i] = 0\n",
    "        b[i] = 0\n",
    "        c[i] = 0\n",
    "df_copy[:,7] = a[:,0]            \n",
    "df_copy = np.append(df_copy, b, 1)\n",
    "df_copy = np.append(df_copy, c, 1)\n",
    "cols[7] = 'Embarked:C'\n",
    "cols.append('Embarked:Q')\n",
    "cols.append('Embarked:S')\n",
    "df = pd.DataFrame(df_copy, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d9aeb64916fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mohe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder(categorical_features=[1])\n",
    "q = ohe.fit_transform(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the PassengerID is not important in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols[:8]  + cols[9:]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We still have NaN value in Age <br>\n",
    "#### Let think of something to fix the nan value in Age<br>\n",
    "#### we can train another model to predict the value for age, so we enter the predict from this model to the missing age value.<br>\n",
    "#### Here we use decision tree to fill in the NaN value in Age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_temp = df[cols[1:]]\n",
    "c = x_temp.columns.tolist()\n",
    "c = c[2:] + c[:2]\n",
    "x_temp = x_temp[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = x_temp.dropna(subset=['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_NaN = x_temp[x_temp.isnull().any(axis=1)]\n",
    "age_NaN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_x = age.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_y = age.iloc[:,0]\n",
    "age_y = age_y.values.astype('int')\n",
    "age_y = age_y.reshape(age_y.shape[0],1)\n",
    "age_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_X = age_x.values.astype('float')\n",
    "age_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test, ay_train, ay_test = train_test_split(age_X, age_y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(a_train, ay_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#29487d'>We can find the model is underfitting which has high bias, so the cost (error) increase to the infinit</font>\n",
    "  - <font size='3em'>One possible is that our data has different scale\n",
    "  <br>\n",
    "  <br>\n",
    "  => So we are going to apply the feature scaler (mean normalization)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_std = np.std(a_train,axis=0)\n",
    "train_mean = np.mean(a_train,axis=0)\n",
    "a_train_std = (a_train- train_mean)* (1/train_std)\n",
    "\n",
    "test_std = np.std(a_test,axis=0)\n",
    "test_mean = np.mean(a_test,axis=0)\n",
    "a_test_std = (a_test- test_mean)* (1/test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(a_train_std, ay_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#29487d' size='3em'>We can see the cost decreasing through out the iteration, but not converge yet.\n",
    "    <br>\n",
    "    <br>\n",
    "    Two Possible to solve this problem:\n",
    "    <ul>\n",
    "        <li>Need more iteration</li>\n",
    "        <li>Increase the learning rate</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <br>\n",
    "    <font size='5em'> Decrease the learning rate:</font>\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [3,1,0.9,0.5,0.3,0.1,0.03]\n",
    "for i in learning_rate:\n",
    "    print('The result for learning rate: %f'% i)\n",
    "    lr.set_eta(i)\n",
    "    lr.fit(a_train_std, ay_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#29487d' size='3em'>\n",
    "    The learning rate doesnt change to much \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.set_niter(5000)\n",
    "lr.fit(a_train_std, ay_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Learning_Curve(set_size,Jtrain,Jtest):\n",
    "    plt.plot(set_size,np.array(Jtrain))\n",
    "    plt.plot(set_size,np.array(Jtest))\n",
    "    plt.legend(['Training Error','Test Error'])\n",
    "    plt.xlabel('Dataset size')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Model response to dataset size')\n",
    "    plt.ylim(0,160)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "Jtrain_age = []\n",
    "Jtest_age = []\n",
    "for i in range(1,a_test.shape[0] + 1):\n",
    "    print('number of subset: %d' % i, flush=True)\n",
    "    model = LinearRegression()\n",
    "    model.fit(a_train_std[:i,:], ay_train[:i,])\n",
    "    theta = model.get_theta()\n",
    "    a_train_std_t = np.concatenate((np.ones((a_train_std.shape[0],1)), a_train_std),1)\n",
    "    a_test_std_t = np.concatenate((np.ones((a_test_std.shape[0],1)), a_test_std),1)\n",
    "    Jtrain_age.append( ((a_train_std_t[:i,:].dot(theta) - ay_train[:i,:]) ** 2).sum() * (1/(2*i)))\n",
    "    Jtest_age.append(((a_test_std_t[:i,:].dot(theta) - ay_test[:i,:]) ** 2).sum()* (1/(2*i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_Learning_Curve( list(range(1,a_test.shape[0] + 1)),Jtrain_age[:a_test.shape[0] + 1], Jtest_age[:a_test.shape[0] + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that when training size increase. According to the plot of learning curve, the error is too high\n",
    "### we plot the relationship between age and different feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_col = age_x.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .5, wspace=0.5)\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(0,len(age_col)):\n",
    "    axs[i].scatter(df[age_col[i]], df.Age)\n",
    "    axs[i].set_title(age_col[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Age'], df['Survived'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Survived')\n",
    "plt.title('survival by Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see we are hard to predict Age by existing feature and survival does not have obvious relation\n",
    "### So we simply drop the Age column that contain NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Age']) \n",
    "x = df[cols[1:]]\n",
    "y = df[cols[0]]\n",
    "cols = df.columns.tolist()\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see it doesnt contain Null value anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After we finish our preprocessing data, we can begin to predict our survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review the Features we have right now\n",
    " - ### Pclass: Ticket class\n",
    " - ### Sex: sex\n",
    " - ### Sex: \n",
    "    - #### 1 = Male \n",
    "    - #### 0 = Female\n",
    " - ### SibSp: Number of siblings/spouses aboard the Titanic\n",
    " - ### Parch: Number of parents/children aboard the Titanic\n",
    " - ### Ticket: Ticket number\n",
    " - ### Fareï¼š Passenger fare\n",
    " - ### Embarked: Port of Embarkation\n",
    "    - #### C = Cherbourg \n",
    "    - #### Q = Queenstown\n",
    "    - #### s = Southampton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see,  We have 712 training data and 9 features in this table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a binary classification problem and the data is not complex\n",
    "## so we have two choice for this kind of problem:\n",
    " - ### Logistic Regression\n",
    " - ### Support Vector Machines (with kernal or without kernal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression vs Support Vector machine ( a.k.a SVM )\n",
    "## <p>We will compare this two algorighm first</p>\n",
    "## <p>n = number of features, m = number of training examples : </p>\n",
    "- ### <p>If n is large (relative to m)\n",
    "    - ##### Use logistic regression or SVM without kernel(linear kernel)</p>\n",
    "- ### <p>If n is small and m is intermediate (n = 1 ~ 1000, m = 1 ~ 10,000),\n",
    "    - ##### Use SVM with Gaussian Kernel</p>\n",
    "- ### <p>If n is small and m is large,\n",
    "    - ##### Create/Add more features, then use logistic kernel or SVM without a kernel</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network likely to work well for most of these setting\n",
    "## but many be slower to train and may have huge local optima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X, y = (examples, features)\n",
    "## Theta = (thetas,)\n",
    "class LogisticRegression():\n",
    "    def __init__(self, reg_lambda = 0, eta = 0.01, niter=1500):\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.eta = eta\n",
    "        self.niter = niter\n",
    "        self.theta = None\n",
    "        self.cost = []\n",
    "        self.result = None\n",
    "        self.m = 0\n",
    "###################  Train the model  ##################\n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1+ math.e ** (-1.0 * z))\n",
    "    def fit(self,X, y):\n",
    "        if type(X) == type(pd.DataFrame()):\n",
    "            X = X.values\n",
    "        if type(y) == type(pd.DataFrame()) or type(y) is type(pd.Series()):\n",
    "            y = y.values\n",
    "        X = np.concatenate((np.ones((X.shape[0],1)), X),1)\n",
    "        reg_lambda = self.reg_lambda\n",
    "        if len(y.shape) == 1:\n",
    "#             print('y has been reshape')\n",
    "            y = y.reshape(y.shape[0],1)\n",
    "        if len(X.shape) == 1:\n",
    "#             print('X has been reshape')\n",
    "            X = X.reshape(X.shape[0],1)\n",
    "        m = len(y)\n",
    "        self.m = m\n",
    "        Cost = []\n",
    "###################  Compute Cost Function for Linear Regression #################\n",
    "        def _cost(theta):\n",
    "            J = self.CostFunction(theta, X,y,reg_lambda)\n",
    "            Cost.append(J)\n",
    "            return J\n",
    "        def _grad(theta):\n",
    "            self.cost = []\n",
    "            reg_penalty = reg_lambda/(m) * (theta[1:]).sum()\n",
    "            theta = theta.reshape(theta.shape[0],1)\n",
    "            grad = 1/(m) * np.transpose(X).dot(self.sigmoid(X.dot(theta)).reshape(y.shape[0],y.shape[1]) - y) +  reg_penalty\n",
    "            grad = grad.flatten()\n",
    "            return grad\n",
    "        \n",
    "################### Broyden-Fletcher-Goldfarb-Shanno Algorithm ###################\n",
    "        ## use this algorithm to converge gradient\n",
    "        #theta = np.zeros((X.shape[1],1))\n",
    "        init_theta = np.zeros(X.shape[1],)\n",
    "#             print('\\rIteration:  %d || Cost : %f'  % (i , _cost(theta)), flush=True,end='')\n",
    "        # fmin_bfgs need to use 1-d array (shape = (n,)) instead of 2-d or more\n",
    "        [xopt, fopt, gopt, Bopt, func_calls, grad_calls, warnflg,allvecs] = optimize.fmin_bfgs(f=_cost,\n",
    "                                                                                               x0=init_theta,\n",
    "                                                                                               fprime=_grad,\n",
    "                                                                                               disp=True,\n",
    "                                                                                               maxiter = self.niter,\n",
    "                                                                                               full_output=True,\n",
    "                                                                                               retall=True)\n",
    "        #xopt = optimize.minimize(fun=_cost, x0=init_theta, method='CG', jac=_grad)\n",
    "#         print('\\nTheta is: ', end='')\n",
    "#         for i in range(0, theta.shape[0]):\n",
    "#             print('%f, ' % theta[i], end='')\n",
    "#         print()\n",
    "        self.theta = xopt\n",
    "        self.cost = Cost\n",
    "###################  Predict the New Data  ##################\n",
    "    def predict(self,newData):\n",
    "        if len(self.theta.shape) == 1:\n",
    "            theta = self.theta.reshape(self.theta.shape[0],1)\n",
    "        if len(newData.shape) == 1:\n",
    "            newData = newData.reshape(newData.shape[0],1)\n",
    "        newData = np.concatenate((np.ones((newData.shape[0],1)), newData),1)\n",
    "        h = self.sigmoid(newData.dot(theta)).astype(float)\n",
    "        return (h >= 0.5).astype(int).flatten()\n",
    "    def getCost(self):\n",
    "        return self.cost\n",
    "    def set_eta(self, eta):\n",
    "        self.cost = []\n",
    "        self.eta = eta\n",
    "    def set_niter(self, niter):\n",
    "        self.niter=niter\n",
    "    def set_panelty(self, p):\n",
    "        self.reg_lambda = p\n",
    "    def get_theta(self):\n",
    "        return self.theta\n",
    "    def CostFunction(self, theta,X,y,reg_lambda):\n",
    "        m = self.m\n",
    "        g = self.sigmoid(X.dot(theta)).astype(np.float)\n",
    "        if len(g.shape) is 1:\n",
    "            g = g.reshape(g.shape[0],1)\n",
    "        theta = theta.reshape(theta.shape[0],1) \n",
    "        reg_penalty = reg_lambda/(2/m) * (theta[1:] ** 2).sum()\n",
    "        J = float(-1)/(m) * (np.transpose(y).dot(np.log(g)) + np.transpose(1-y).dot(np.log(1-g))).sum()+  reg_penalty\n",
    "        return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.values.astype(np.float32)\n",
    "Y = y.values.astype(np.float32)\n",
    "logr.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.bincount(pred == Y)\n",
    "print('The model accuracy on the dataset %f\\nThis is trying to see how well it converge' %  (a[1]/(a[1] + a[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = logr.getCost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(cost)), cost)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('The Cost in different Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we can see the logistic regression implementation seem work correctly, \n",
    "## we want to do a furture check by using cross-validation set to see the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'X_train\\'s shape:  (%d, %d)' % (X_train.shape[0],X_train.shape[1]))\n",
    "print( 'y_train\\' shape:  (%d,)' % (y_train.shape[0],))\n",
    "print( 'X_cv\\' shape:  (%d, %d)' % (X_cv.shape[0],X_cv.shape[1]))\n",
    "print( 'y_cv\\' shape:  (%d,)' % (y_cv.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logrr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logrr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = logrr.predict(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Learning_Curve(set_size,Jtrain,Jtest):\n",
    "    plt.plot(set_size,np.array(Jtrain))\n",
    "    plt.plot(set_size,np.array(Jtest))\n",
    "    plt.legend(['Training Error','Test Error'])\n",
    "    plt.xlabel('Dataset size')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Model response to dataset size')\n",
    "    plt.ylim(0, 2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jtrain = []\n",
    "Jtest = []\n",
    "for i in range(1,X_cv.shape[0] + 1):\n",
    "    print('number of subset: %d' % i, flush=True)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train[:i,:], y_train[:i,])\n",
    "    theta = model.get_theta()\n",
    "    X_cv_t = np.concatenate((np.ones((X_cv.shape[0],1)), X_cv),1)\n",
    "    Jtrain.append(model.getCost()[-1])\n",
    "    Jtest.append(model.CostFunction(theta,X_cv_t,y_cv,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_Learning_Curve(range(1,X_cv.shape[0] + 1),Jtrain,Jtest)\n",
    "pred_cv = logrr.predict(X_cv)\n",
    "a_cv = np.bincount(pred_cv == y_cv)\n",
    "cv_accuracy = a_cv[1]/(a_cv[1] + a_cv[0])\n",
    "print('Cross-Validation accuracy: %f ' % cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Vector Machine (SVM) with Guassian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = svm.SVC(kernel='rbf', random_state=0, C = 1)\n",
    "sv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sv.predict(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy using svm with kernal: %2f' % accuracy_score(y_cv, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We might want to ues feature \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_cv_std = sc.transform(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = svm.SVC(kernel='rbf', random_state=0, C = 1)\n",
    "sv.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_std = sv.predict(X_cv_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy using svm with kernal: %2f' % accuracy_score(y_cv, y_pred_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,X_cv.shape[0] + 1):\n",
    "    print('number of subset: %d' % i, flush=True)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train[:i,:], y_train[:i,])\n",
    "    theta = model.get_theta()\n",
    "    X_cv_t = np.concatenate((np.ones((X_cv.shape[0],1)), X_cv),1)\n",
    "    Jtrain.append(model.getCost()[-1])\n",
    "    Jtest.append(model.CostFunction(theta,X_cv_t,y_cv,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [0.001,0.003,0.01, 0.03, 0.1, 0.3, 1, 3, 10]\n",
    "accuarcy = []\n",
    "for i in index:\n",
    "    model = svm.SVC(kernel='rbf', random_state=0, C = i)\n",
    "    model.fit(X_train_std,y_train)\n",
    "    y_pred_std = model.predict(X_cv_std)\n",
    "    accuarcy.append(accuracy_score(y_cv, y_pred_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(index, accuarcy)\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"The Accuracy with different parameter C \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "accuarcy = []\n",
    "for i in range(1,100):\n",
    "    model = svm.SVC(kernel='rbf', random_state=0, C = 0.01, gamma=i)\n",
    "    model.fit(X_train_std,y_train)\n",
    "    y_pred_std = model.predict(X_cv_std)\n",
    "    accuarcy.append(accuracy_score(y_cv, y_pred_std))\n",
    "    index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(index, accuarcy)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"The Accuracy with different parameter gamma \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train\n",
    "X_cv_copy =X_cv\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder(categorical_features=[1])\n",
    "q = ohe.fit_transform(X_train_copy).toarray()\n",
    "e = ohe.fit_transform(X_cv_copy).toarray()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(q)\n",
    "q = sc.transform(q)\n",
    "e = sc.transform(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = svm.SVC(kernel='rbf', random_state=0, C = 1)\n",
    "sv.fit(q,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_std = sv.predict(e)\n",
    "print('Accuracy using svm with kernal: %2f' % accuracy_score(y_cv, y_pred_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entro_tree = DecisionTreeClassifier(criterion= 'entropy', random_state = 0)\n",
    "entro_tree.fit(age_x, age_y)\n",
    "export_graphviz(entro_tree, out_file= 'temp.dot', feature_names=c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entro_tree = DecisionTreeClassifier(criterion= 'entropy', random_state = 0)\n",
    "gini_tree = DecisionTreeClassifier(criterion= 'gini', random_state = 1)\n",
    "entro_tree.fit(x, y)\n",
    "gini_tree.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three columns that have the NaN value and this three columns has to deal with later. However, we find the relation (correlation matrix) with the target feature first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot matrix\n",
    "## Pair- wise corrlations between the different features in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', context='notebook')\n",
    "exp = df[:][:1000]\n",
    "sns.pairplot(exp[cols])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
